{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4937d5e8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import optuna\n",
    "#import torch.nn.functional as F\n",
    "#import csv\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921274f",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521d7c5",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device init\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "W_DECAY = 1e-5\n",
    "LEARN_RATE = 1e-4\n",
    "EPOCH_NUM = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BETA = 0.1 # for the KL divergence term\n",
    "BETA_INCREASE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bfcdb8",
   "metadata": {},
   "source": [
    "## Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms.v2 as transforms\n",
    "\n",
    "def create_data():\n",
    "    # ---INITIALIZE DATASET ---\n",
    "    #Convert pilimage dataset to a standart numpy dataset\n",
    "    dataset = MNIST(\n",
    "        root='./data',\n",
    "        download=True,  # Add this to download the dataset if needed\n",
    "        transform= transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    TRIM_LEN = int(10_000)  # 60,000 - 10,000 = 50,000 SAMPLES\n",
    "    TRAIN_PORTION = 0.95 # 95% training 5% everything else\n",
    "    TRAIN_LEN = int((len(dataset) - TRIM_LEN) * TRAIN_PORTION)\n",
    "    \n",
    "    # ---SPLIT DATASET---\n",
    "    train_ds, test_ds, _ = random_split(\n",
    "        dataset,  # Split the dataset, not the dataloader!\n",
    "        [TRAIN_LEN, len(dataset) - TRIM_LEN - TRAIN_LEN, TRIM_LEN]\n",
    "    )\n",
    "    #print(f\"train length: {len(train_ds)} test_length: {len(test_ds)}\")\n",
    "    \n",
    "    # ---CREATE DATALOADERS from the split datasets---\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6dbc42",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, optimizer, epoch_num):\n",
    "    # Method 1: One-liner\n",
    "    #single_batch = next(batch_idx(train_loader))[0].to(device)\n",
    "    global BETA\n",
    "    #loss_func = nn.BCELoss(reduction='sum')\n",
    "    loss_func = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    for batch_idx, single_batch in enumerate(train_loader):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        single_batch = single_batch[0].to(device)\n",
    "        # ---------Feed Forward---------\n",
    "        # Extract just the generated images for now\n",
    "        mean,log_var,img_gen_batch = model.forward(single_batch)\n",
    "\n",
    "        #---------Back Prop---------\n",
    "        # Loss is calculated by the batch's mean\n",
    "        \n",
    "        flat_sample = torch.flatten(single_batch,start_dim=1)\n",
    "        img_gen_batch = torch.flatten(img_gen_batch,start_dim=-1)[0]\n",
    "\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())#.mean()\n",
    "\n",
    "        loss = loss_func(img_gen_batch, flat_sample) + BETA*kl_div\n",
    "\n",
    "        if batch_idx%100==0:\n",
    "            print(f\"batch num {batch_idx}: {loss.item()} at epoch: {epoch_num+1}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    if (BETA<1.0):\n",
    "            #BETA*=1 + 1e-4\n",
    "            BETA+=BETA_INCREASE\n",
    "    torch.save(model.state_dict(), \"vae_model.pth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90b621",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "my_vae = VAE(device).to(device)\n",
    "optim = torch.optim.Adam(params=my_vae.parameters(),\n",
    "                         lr = LEARN_RATE, weight_decay=W_DECAY)\n",
    "\n",
    "train_loader,test_loader = create_data()\n",
    "\n",
    "\n",
    "for i in range(EPOCH_NUM):\n",
    "    train_vae(model=my_vae, train_loader=train_loader,\n",
    "            optimizer=optim,epoch_num=i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
